{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Food Demand Forecasting\n\n## Problem Statement\nPredict demand for the next 10 weeks (146-155) for center-meal combinations.\n\n## Evaluation Metric\n**100 \u00d7 RMSLE** (Root Mean Squared Logarithmic Error)\n\n## Approach\nUse **sklearn Pipeline with DictVectorizer** for production-ready ML with **interactive Plotly visualizations**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Import Libraries"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Load Data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test_QoiMO9B.csv')\n",
    "fulfillment_center = pd.read_csv('data/fulfilment_center_info.csv')\n",
    "meal_info = pd.read_csv('data/meal_info.csv')\n",
    "\n",
    "print(f\"Train: {train.shape}\")\n",
    "print(f\"Test: {test.shape}\")\n",
    "print(f\"Centers: {fulfillment_center.shape}\")\n",
    "print(f\"Meals: {meal_info.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "display(train.head())\n",
    "display(fulfillment_center.head())\n",
    "display(meal_info.head())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Combine Train and Test"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "combined = pd.concat([train, test], ignore_index=True)\n",
    "combined = combined.merge(fulfillment_center, on='center_id', how='left')\n",
    "combined = combined.merge(meal_info, on='meal_id', how='left')\n",
    "print(f\"Combined: {combined.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Exploratory Data Analysis (Interactive Plotly Visualizations)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_data = combined[combined['is_train'] == 1].copy()\n",
    "\n",
    "print(f\"Mean orders: {train_data['num_orders'].mean():.2f}\")\n",
    "print(f\"Median orders: {train_data['num_orders'].median():.2f}\")\n",
    "print(f\"Std orders: {train_data['num_orders'].std():.2f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Distribution plots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Distribution of Orders', 'Log-Transformed Distribution')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=train_data['num_orders'], nbinsx=50, name='Orders'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=np.log1p(train_data['num_orders']), nbinsx=50, name='Log(Orders+1)'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=400,\n",
    "    showlegend=False,\n",
    "    title_text=\"Order Distribution Analysis\"\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Number of Orders\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Log(Orders + 1)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Weekly trends\n",
    "weekly = train_data.groupby('week')['num_orders'].agg(['mean', 'sum']).reset_index()\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    subplot_titles=('Average Orders per Week', 'Total Orders per Week'),\n",
    "    vertical_spacing=0.12\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=weekly['week'], y=weekly['mean'], mode='lines+markers', \n",
    "               name='Avg Orders', line=dict(color='blue', width=2)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=weekly['week'], y=weekly['sum'], mode='lines+markers',\n",
    "               name='Total Orders', line=dict(color='orange', width=2)),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(height=700, showlegend=False, title_text=\"Weekly Order Trends\")\n",
    "fig.update_xaxes(title_text=\"Week\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Average Orders\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Total Orders\", row=2, col=1)\n",
    "fig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Category analysis - Center Type\n",
    "center_orders = train_data.groupby('center_type')['num_orders'].mean().sort_values(ascending=False).reset_index()\n",
    "\n",
    "fig = px.bar(center_orders, x='center_type', y='num_orders',\n",
    "             title='Average Orders by Center Type',\n",
    "             labels={'num_orders': 'Average Orders', 'center_type': 'Center Type'},\n",
    "             color='num_orders', color_continuous_scale='Blues')\n",
    "fig.update_layout(height=400, showlegend=False)\n",
    "fig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Category analysis - Meal Category\n",
    "category_orders = train_data.groupby('category')['num_orders'].mean().sort_values(ascending=False).reset_index()\n",
    "\n",
    "fig = px.bar(category_orders, x='category', y='num_orders',\n",
    "             title='Average Orders by Meal Category',\n",
    "             labels={'num_orders': 'Average Orders', 'category': 'Category'},\n",
    "             color='num_orders', color_continuous_scale='Oranges')\n",
    "fig.update_layout(height=400, showlegend=False)\n",
    "fig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Category analysis - Cuisine\n",
    "cuisine_orders = train_data.groupby('cuisine')['num_orders'].mean().sort_values(ascending=False).reset_index()\n",
    "\n",
    "fig = px.bar(cuisine_orders, x='cuisine', y='num_orders',\n",
    "             title='Average Orders by Cuisine',\n",
    "             labels={'num_orders': 'Average Orders', 'cuisine': 'Cuisine'},\n",
    "             color='num_orders', color_continuous_scale='Greens')\n",
    "fig.update_layout(height=400, showlegend=False)\n",
    "fig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Promotion analysis\n",
    "promo_data = train_data.groupby(['emailer_for_promotion', 'homepage_featured'])['num_orders'].mean().reset_index()\n",
    "promo_data['promotion_type'] = promo_data.apply(\n",
    "    lambda x: f\"Email: {x['emailer_for_promotion']}, Homepage: {x['homepage_featured']}\", axis=1\n",
    ")\n",
    "\n",
    "fig = px.bar(promo_data, x='promotion_type', y='num_orders',\n",
    "             title='Average Orders by Promotion Type',\n",
    "             labels={'num_orders': 'Average Orders', 'promotion_type': 'Promotion'},\n",
    "             color='num_orders', color_continuous_scale='Purples')\n",
    "fig.update_layout(height=400, showlegend=False)\n",
    "fig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Feature Engineering\n\n**Key point**: Keep categorical variables as strings for DictVectorizer to handle"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Price features\n",
    "    df['discount'] = df['base_price'] - df['checkout_price']\n",
    "    df['discount_percentage'] = (df['discount'] / df['base_price']) * 100\n",
    "    df['discount_percentage'] = df['discount_percentage'].fillna(0)\n",
    "    \n",
    "    # Promotional features\n",
    "    df['total_promotion'] = df['emailer_for_promotion'] + df['homepage_featured']\n",
    "    \n",
    "    # Time-based features\n",
    "    df['week_mod_4'] = df['week'] % 4\n",
    "    df['week_mod_13'] = df['week'] % 13\n",
    "    df['week_mod_52'] = df['week'] % 52\n",
    "    \n",
    "    # Convert categorical to strings (for DictVectorizer)\n",
    "    categorical_cols = ['center_id', 'meal_id', 'city_code', 'region_code',\n",
    "                       'center_type', 'category', 'cuisine']\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "combined_features = create_features(combined)\n",
    "print(f\"Features created: {combined_features.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Prepare Train/Validation/Test Sets"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_df = combined_features[combined_features['is_train'] == 1].copy()\n",
    "test_df = combined_features[combined_features['is_train'] == 0].copy()\n",
    "\n",
    "exclude_cols = ['id', 'num_orders', 'is_train']\n",
    "feature_cols = [col for col in train_df.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(feature_cols)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X = train_df[feature_cols]\n",
    "y = train_df['num_orders']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test = test_df[feature_cols]\n",
    "\n",
    "# Sample for faster tuning\n",
    "SAMPLE_SIZE = 50000\n",
    "if len(X_train) > SAMPLE_SIZE:\n",
    "    sample_indices = np.random.choice(len(X_train), SAMPLE_SIZE, replace=False)\n",
    "    X_train_sample = X_train.iloc[sample_indices].copy()\n",
    "    y_train_sample = y_train.iloc[sample_indices].copy()\n",
    "    print(f\"Created sample of {SAMPLE_SIZE} records\")\n",
    "else:\n",
    "    X_train_sample = X_train\n",
    "    y_train_sample = y_train\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Sample: {X_train_sample.shape}\")\n",
    "print(f\"Val: {X_val.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Convert to Dictionary Format\n\nDictVectorizer requires list of dictionaries"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train_dict = X_train.to_dict('records')\n",
    "X_train_sample_dict = X_train_sample.to_dict('records')\n",
    "X_val_dict = X_val.to_dict('records')\n",
    "\n",
    "print(f\"Converted to dict format\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Define RMSLE Metric"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    return np.sqrt(np.mean((np.log1p(y_true) - np.log1p(y_pred)) ** 2))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle, greater_is_better=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Model Comparison with DictVectorizer Pipelines"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': Lasso(alpha=1.0, random_state=42),\n",
    "    'Ridge': Ridge(alpha=1.0, random_state=42),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "results = []\n",
    "print(f\"{'Model':<20} {'Train RMSLE':<15} {'Val RMSLE':<15} {'100*RMSLE':<15}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        pipeline = Pipeline([\n",
    "            ('dict_vectorizer', DictVectorizer(sparse=False)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train_dict, y_train)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(X_train_dict)\n",
    "        y_val_pred = pipeline.predict(X_val_dict)\n",
    "        \n",
    "        train_rmsle = rmsle(y_train, y_train_pred)\n",
    "        val_rmsle = rmsle(y_val, y_val_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Train RMSLE': train_rmsle,\n",
    "            'Val RMSLE': val_rmsle,\n",
    "            'Score (100*RMSLE)': 100 * val_rmsle,\n",
    "            'Pipeline': pipeline\n",
    "        })\n",
    "        \n",
    "        print(f\"{name:<20} {train_rmsle:<15.4f} {val_rmsle:<15.4f} {100*val_rmsle:<15.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name:<20} Error: {str(e)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Val RMSLE')\n",
    "print(\"\\nBest Model:\")\n",
    "display(results_df[['Model', 'Val RMSLE', 'Score (100*RMSLE)']].head())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Interactive model comparison chart\n",
    "fig = px.bar(results_df, x='Model', y='Score (100*RMSLE)',\n",
    "             title='Model Comparison (Lower is Better)',\n",
    "             labels={'Score (100*RMSLE)': '100 \u00d7 RMSLE'},\n",
    "             color='Score (100*RMSLE)',\n",
    "             color_continuous_scale='RdYlGn_r',\n",
    "             text='Score (100*RMSLE)')\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
    "fig.update_layout(height=500, showlegend=False)\n",
    "fig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Hyperparameter Tuning for Best Model"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"Best Model: {best_model_name}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define param grids for models worth tuning\n",
    "param_grids = {\n",
    "    'XGBoost': {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [5, 7],\n",
    "        'model__learning_rate': [0.05, 0.1],\n",
    "        'model__subsample': [0.8, 0.9]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [10, 15, 20],\n",
    "        'model__min_samples_split': [2, 5]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [3, 5],\n",
    "        'model__learning_rate': [0.05, 0.1]\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model__max_depth': [5, 10, 15, 20],\n",
    "        'model__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Check if best model has a tuning grid\n",
    "if best_model_name in param_grids:\n",
    "    print(f\"Found tuning grid for {best_model_name}\")\n",
    "    \n",
    "    # Get the original model from our models dict\n",
    "    base_model = models[best_model_name]\n",
    "    \n",
    "    # Create fresh pipeline with the base model\n",
    "    pipeline = Pipeline([\n",
    "        ('dict_vectorizer', DictVectorizer(sparse=False)),\n",
    "        ('model', base_model)\n",
    "    ])\n",
    "    \n",
    "    # Run grid search\n",
    "    grid = RandomizedSearchCV(\n",
    "        pipeline, \n",
    "        param_grids[best_model_name], \n",
    "        n_iter=20,\n",
    "        random_state=42,\n",
    "        cv=3, \n",
    "        scoring=rmsle_scorer, \n",
    "        n_jobs=-1, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"Starting random search...\")\n",
    "    grid.fit(X_train_dict, y_train)\n",
    "    \n",
    "    print(\"\\nBest params:\", grid.best_params_)\n",
    "    best_pipeline = grid.best_estimator_\n",
    "    \n",
    "    # Show improvement\n",
    "    original_val_rmsle = results_df.iloc[0]['Val RMSLE']\n",
    "    tuned_val_pred = best_pipeline.predict(X_val_dict)\n",
    "    tuned_val_rmsle = rmsle(y_val, tuned_val_pred)\n",
    "    improvement = ((original_val_rmsle - tuned_val_rmsle) / original_val_rmsle) * 100\n",
    "    print(f\"\\nOriginal RMSLE: {original_val_rmsle:.4f}\")\n",
    "    print(f\"Tuned RMSLE: {tuned_val_rmsle:.4f}\")\n",
    "    print(f\"Improvement: {improvement:.2f}%\")\n",
    "else:\n",
    "    print(f\"No tuning grid defined for {best_model_name}\")\n",
    "    print(\"Using default parameters from comparison\")\n",
    "    best_pipeline = results_df.iloc[0]['Pipeline']\n",
    "    print(\"\\nTo add hyperparameter tuning for this model:\")\n",
    "    print(f\"Add '{best_model_name}' to param_grids dict above\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. Evaluate Best Pipeline"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_val_pred = best_pipeline.predict(X_val_dict)\n",
    "val_rmsle_final = rmsle(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Final Validation RMSLE: {val_rmsle_final:.4f}\")\n",
    "print(f\"Final Score (100*RMSLE): {100*val_rmsle_final:.4f}\")\n",
    "\n",
    "# Pipeline details\n",
    "dict_vec = best_pipeline.named_steps['dict_vectorizer']\n",
    "print(f\"\\nPipeline Steps: {list(best_pipeline.named_steps.keys())}\")\n",
    "print(f\"Input features: {len(feature_cols)}\")\n",
    "print(f\"Vectorized features: {len(dict_vec.feature_names_)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12. Feature Importance (if available)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = best_pipeline.named_steps['model']\n",
    "\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    dict_vec = best_pipeline.named_steps['dict_vectorizer']\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': dict_vec.feature_names_,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Interactive feature importance plot\n",
    "    top_n = 20\n",
    "    fig = px.bar(feature_importance.head(top_n), \n",
    "                 x='importance', y='feature',\n",
    "                 orientation='h',\n",
    "                 title=f'Top {top_n} Most Important Features',\n",
    "                 labels={'importance': 'Importance', 'feature': 'Feature'},\n",
    "                 color='importance',\n",
    "                 color_continuous_scale='Viridis')\n",
    "    \n",
    "    fig.update_layout(height=600, yaxis={'categoryorder':'total ascending'}, showlegend=False)\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\nTop 15 Features:\")\n",
    "    display(feature_importance.head(15))\n",
    "else:\n",
    "    print(\"Model doesn't have feature_importances_\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 13. Retrain on Full Data and Make Predictions"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Retrain on full training data\n",
    "X_full_dict = X.to_dict('records')\n",
    "best_pipeline.fit(X_full_dict, y)\n",
    "print(\"\u2713 Retrained on full data\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "X_test_dict = X_test.to_dict('records')\n",
    "predictions = best_pipeline.predict(X_test_dict)\n",
    "predictions = np.maximum(predictions, 0)\n",
    "\n",
    "print(f\"Predictions: {len(predictions)}\")\n",
    "print(f\"Min: {predictions.min():.2f}\")\n",
    "print(f\"Max: {predictions.max():.2f}\")\n",
    "print(f\"Mean: {predictions.mean():.2f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize prediction distribution\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=predictions, nbinsx=50, name='Test Predictions'))\n",
    "fig.update_layout(\n",
    "    title='Distribution of Test Predictions',\n",
    "    xaxis_title='Predicted Orders',\n",
    "    yaxis_title='Frequency',\n",
    "    height=400\n",
    ")\n",
    "fig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 14. Save Pipeline and Create Submission"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_pipeline, f)\n",
    "print(\"\u2713 Pipeline saved as 'final_model.pkl'\")\n",
    "\n",
    "with open('feature_cols.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_cols, f)\n",
    "print(\"\u2713 Feature columns saved\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'num_orders': predictions.round().astype(int)\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\u2713 Submission saved\")\n",
    "display(submission.head(10))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n### Key Points:\n1. \u2705 Used **DictVectorizer** for automatic one-hot encoding\n2. \u2705 **Pipeline** encapsulates entire workflow\n3. \u2705 Compared **7 different models**\n4. \u2705 **Interactive Plotly visualizations** for better EDA\n5. \u2705 Selected best model and tuned hyperparameters\n6. \u2705 Saved complete pipeline in **single pickle file**\n\n### Production Ready:\n- `train.py` uses this exact approach\n- `predict.py` loads pipeline and serves predictions\n- Single artifact for deployment\n\n### Visualizations:\n- All plots are **interactive** (hover, zoom, pan)\n- Professional appearance\n- Better for presentations and reports"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}